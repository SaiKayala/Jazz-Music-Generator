{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from music21 import converter, instrument, note, chord,stream\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense,LSTM,Dropout,Softmax,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs=glob.glob('./trainset-jazz/*.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song=glob.glob('./test_output4.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetNotes():\n",
    "    notes=[]\n",
    "    for file in song:\n",
    "        midi=converter.parse(song[0])\n",
    "        notes_to_parse=[]\n",
    "        try:\n",
    "            parts=instrument.partitionByInstrument(midi)\n",
    "        except:\n",
    "            pass\n",
    "        if parts:\n",
    "            notes_to_parse=parts.parts[0].recurse()\n",
    "        else:\n",
    "            notes_to_parse=midi.flat.notes\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif(isinstance(element, chord.Chord)):\n",
    "                notes.append('.',join(str(n)for n in element.normalOrder))\n",
    "    #with open('data','wb') as filepath:\n",
    "     #   pickle.append(notes,filepath)\n",
    "    return notes\n",
    "            \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=GetNotes()\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_values=sorted(set(item for item in train))\n",
    "n_vocab=len(n_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_int=dict((note,number) for number,note in enumerate(n_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length=64\n",
    "input_network=[]\n",
    "out_network=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(train)-seq_length,1):\n",
    "    se_in=train[i: i+seq_length]\n",
    "    se_out=train[i+seq_length]\n",
    "    input_network.append([notes_int[char] for char in se_in])\n",
    "    out_network.append([notes_int[se_out]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_network=np.reshape(input_network,(len(input_network),seq_length,1))\n",
    "input_network=input_network/float(n_vocab)\n",
    "out_network=keras.utils.np_utils.to_categorical(out_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(in_net,len_seq):\n",
    "    model=Sequential()\n",
    "    model.add(LSTM(seq_length,input_shape=in_net.shape[1:],return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(seq_length,return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(seq_length,return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(len_seq))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model(input_network,n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath = 'weights.best.music3.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True)\n",
    "model.fit(input_network,out_network,epochs=200,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights.best.music3.hdf5')\n",
    "\n",
    "start=np.random.randint(0,len(input_network)-1)\n",
    "int_to_note = dict((number, note) for number, note in enumerate(n_values))\n",
    "\n",
    "pattern=input_network[start]\n",
    "prediction_out=[]\n",
    "for note_index in range(100):\n",
    "    start=np.random.randint(0,len(input_network)-1)\n",
    "    pattern=input_network[start]\n",
    "    prediction_input = np.reshape(pattern, (1, len(pattern), 1))  \n",
    "    #prediction_input = prediction_input / float(n_vocab)  \n",
    "    prediction = model.predict(prediction_input, verbose=0)  \n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_note[index]\n",
    "    prediction_out.append(result)  \n",
    "    np.append(pattern,index)\n",
    "    #n=len(pattern)\n",
    "    #pattern = pattern[1:n]\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi(prediction_output):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    \n",
    "    print('Saving Output file as midi....')\n",
    "\n",
    "    midi_stream.write('midi', fp='test_output4.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_midi(prediction_out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
